{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "251d0306",
   "metadata": {},
   "source": [
    "# Final Project - GAN Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a48618a",
   "metadata": {},
   "source": [
    "Date: 20230508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4ea8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim                  # optimization\n",
    "import torchvision                           # image loading\n",
    "import torchvision.transforms as transforms  # image transformation\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca66db",
   "metadata": {},
   "source": [
    "Check GPU cuba capability here: https://developer.nvidia.com/cuda-gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c438b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f704b4",
   "metadata": {},
   "source": [
    "### Data Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b8f704",
   "metadata": {},
   "source": [
    "Data Size: 28 $\\times$ 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed6a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "# for GAN, it is better to have result as (-1,1) rather than (0,1), \n",
    "# since generator use Tanh() in (-1,1) for final activation (experimental result),\n",
    "# set mean = 0.5 and variance = 0.5 to get (-1,1) [(x-mean)/variance]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e834710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the built-in MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root = './mnist_train.csv',                # save locally\n",
    "    train = True,                             # only need train data\n",
    "    transform = transform,                     # defined in the chrunk above\n",
    "    download = True\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=True                              # make less possible to overfit\n",
    "    # ,num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86247085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check image size\n",
    "imgs, _ = next(iter(dataloader))\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb90e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf7d89",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64de3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "# Input: random noise (normally distributed random numbers) with length of 100\n",
    "# Output: generated image, which has the same size as the input image with size of [1, 28, 28]\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(  # implement linear layer to transforming the input (noise) data to a higher-dimensional space\n",
    "            nn.Linear(100, 256),     # Linear 1: 100 to 256\n",
    "            nn.ReLU(),               # active Linear 1\n",
    "            nn.Linear(256, 512),     # Linear 2: 256 to 512\n",
    "            nn.ReLU(),               # active Linear 2\n",
    "            nn.Linear(512, 1024),    # Linear 3: 512 to 1024\n",
    "            nn.ReLU(),               # active Linear 3\n",
    "            nn.Linear(1024, 784),    # Linear 4: 1024 to 28*28=784\n",
    "            nn.Tanh()                # active to (-1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):            # input x is noise with length of 100\n",
    "        return self.model(x).view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2083a86",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "603c456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "# Input: image with size of [1, 28, 28]\n",
    "# Output: probability values [0,1] for binary classification\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(  # flatten the image\n",
    "            nn.Linear(784, 1024),    # transforming the input image data to a higher-dimensional space first\n",
    "            nn.LeakyReLU(0.2),       \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()              # active to (0, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x.view(x.size(0), -1))\n",
    "    \n",
    "# nn.LeakyReLU(): if x > 0, f(x) = 0; if x < 0, f(x) = a * x, where a is repsents a small gradient value.\n",
    "# LeakyReLU is recommended for discriminator, since if x < 0, RELU outputs f(x) = 0,leading to gradient = 0, \n",
    "# which makes training unable to move further. thus need to mitigate the vanishing gradient problem and stabilize training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a39e9",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab8638d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_image(model, test_input, epoch):\n",
    "    try:\n",
    "        generated_images = model(test_input).detach().cpu()\n",
    "        torchvision.utils.save_image(generated_images, f'epoch_{epoch}.png', nrow=4, normalize=True)\n",
    "        print(f\"Image saved for epoch {epoch}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in save_image: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f421365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible dead kernel when creating plots\n",
    "\n",
    "#def plot_image(model, test_input):\n",
    "#    prediction = np.squeeze(model(test_input).detach().cpu().numpy())\n",
    "#    fig = plt.figure(figsize = (4,4))\n",
    "#    for i in range(16): # prediction.size(0)\n",
    "#        plt.subplot(4, 4, i+1)\n",
    "#        plt.imshow((prediction[i]+1)/2) # recover (-1, 1) to (0, 1) to make prediction plotable\n",
    "#        plt.axis(\"off\")\n",
    "#    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b891b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.randn(16, 100, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55265c5",
   "metadata": {},
   "source": [
    "### Generator and Discriminator Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ab1d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5f96340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply BCELoss to calculate cross entropy loss for binary classification (sigmod output)\n",
    "# if discriminator does not active by Sigmod() (stop at Linear(256, 1)), then BCEWithLogitsLoss() need to be applied\n",
    "criterion = nn.BCELoss() # lost function\n",
    "optimizer_G = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999)) # optimize G parameters\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999)) # optimize D parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b367a4",
   "metadata": {},
   "source": [
    "### GAN Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cd89c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Discriminator Loss: 0.7023011445999146, Generator Loss: 2.8939623832702637\n",
      "Image saved for epoch 0\n",
      "Epoch: 1, Discriminator Loss: 0.41959118843078613, Generator Loss: 3.8927013874053955\n",
      "Image saved for epoch 1\n",
      "Epoch: 2, Discriminator Loss: 0.3332814574241638, Generator Loss: 3.9070262908935547\n",
      "Image saved for epoch 2\n",
      "Epoch: 3, Discriminator Loss: 0.30224746465682983, Generator Loss: 3.759636402130127\n",
      "Image saved for epoch 3\n",
      "Epoch: 4, Discriminator Loss: 0.314322829246521, Generator Loss: 3.45082426071167\n",
      "Image saved for epoch 4\n",
      "Epoch: 5, Discriminator Loss: 0.4873389005661011, Generator Loss: 2.6328206062316895\n",
      "Image saved for epoch 5\n",
      "Epoch: 6, Discriminator Loss: 0.7652638554573059, Generator Loss: 1.8584436178207397\n",
      "Image saved for epoch 6\n",
      "Epoch: 7, Discriminator Loss: 0.7930213809013367, Generator Loss: 1.8457943201065063\n",
      "Image saved for epoch 7\n",
      "Epoch: 8, Discriminator Loss: 0.8019097447395325, Generator Loss: 1.835387110710144\n",
      "Image saved for epoch 8\n",
      "Epoch: 9, Discriminator Loss: 0.8608686327934265, Generator Loss: 1.7242813110351562\n",
      "Image saved for epoch 9\n",
      "Epoch: 10, Discriminator Loss: 0.882615864276886, Generator Loss: 1.7163537740707397\n",
      "Image saved for epoch 10\n",
      "Epoch: 11, Discriminator Loss: 0.90157550573349, Generator Loss: 1.6688085794448853\n",
      "Image saved for epoch 11\n",
      "Epoch: 12, Discriminator Loss: 0.9082944393157959, Generator Loss: 1.644240379333496\n",
      "Image saved for epoch 12\n",
      "Epoch: 13, Discriminator Loss: 0.9242461919784546, Generator Loss: 1.6336535215377808\n",
      "Image saved for epoch 13\n",
      "Epoch: 14, Discriminator Loss: 0.9366937279701233, Generator Loss: 1.6093006134033203\n",
      "Image saved for epoch 14\n",
      "Epoch: 15, Discriminator Loss: 0.9525050520896912, Generator Loss: 1.5754368305206299\n",
      "Image saved for epoch 15\n",
      "Epoch: 16, Discriminator Loss: 0.9545404314994812, Generator Loss: 1.5680358409881592\n",
      "Image saved for epoch 16\n",
      "Epoch: 17, Discriminator Loss: 0.9734025001525879, Generator Loss: 1.5391548871994019\n",
      "Image saved for epoch 17\n",
      "Epoch: 18, Discriminator Loss: 0.9764191508293152, Generator Loss: 1.5250791311264038\n",
      "Image saved for epoch 18\n",
      "Epoch: 19, Discriminator Loss: 0.9795421957969666, Generator Loss: 1.5185973644256592\n",
      "Image saved for epoch 19\n",
      "Epoch: 20, Discriminator Loss: 0.9839520454406738, Generator Loss: 1.5040862560272217\n",
      "Image saved for epoch 20\n",
      "Epoch: 21, Discriminator Loss: 0.986223042011261, Generator Loss: 1.5010554790496826\n",
      "Image saved for epoch 21\n",
      "Epoch: 22, Discriminator Loss: 0.9839579463005066, Generator Loss: 1.507849931716919\n",
      "Image saved for epoch 22\n",
      "Epoch: 23, Discriminator Loss: 0.9863666892051697, Generator Loss: 1.502592921257019\n",
      "Image saved for epoch 23\n",
      "Epoch: 24, Discriminator Loss: 0.9806482195854187, Generator Loss: 1.5019577741622925\n",
      "Image saved for epoch 24\n",
      "Epoch: 25, Discriminator Loss: 0.9854392409324646, Generator Loss: 1.5014199018478394\n",
      "Image saved for epoch 25\n",
      "Epoch: 26, Discriminator Loss: 0.9895319938659668, Generator Loss: 1.4857630729675293\n",
      "Image saved for epoch 26\n",
      "Epoch: 27, Discriminator Loss: 0.9816014170646667, Generator Loss: 1.507182240486145\n",
      "Image saved for epoch 27\n",
      "Epoch: 28, Discriminator Loss: 0.985799252986908, Generator Loss: 1.503769874572754\n",
      "Image saved for epoch 28\n",
      "Epoch: 29, Discriminator Loss: 0.9794350266456604, Generator Loss: 1.503874659538269\n",
      "Image saved for epoch 29\n",
      "Epoch: 30, Discriminator Loss: 0.9857248663902283, Generator Loss: 1.4887136220932007\n",
      "Image saved for epoch 30\n",
      "Epoch: 31, Discriminator Loss: 0.9841248393058777, Generator Loss: 1.4890937805175781\n",
      "Image saved for epoch 31\n",
      "Epoch: 32, Discriminator Loss: 0.9778950810432434, Generator Loss: 1.4969292879104614\n",
      "Image saved for epoch 32\n",
      "Epoch: 33, Discriminator Loss: 0.9805156588554382, Generator Loss: 1.4976693391799927\n",
      "Image saved for epoch 33\n",
      "Epoch: 34, Discriminator Loss: 0.9815430641174316, Generator Loss: 1.4892942905426025\n",
      "Image saved for epoch 34\n",
      "Epoch: 35, Discriminator Loss: 0.9834862947463989, Generator Loss: 1.492548942565918\n",
      "Image saved for epoch 35\n",
      "Epoch: 36, Discriminator Loss: 0.9800727367401123, Generator Loss: 1.4901858568191528\n",
      "Image saved for epoch 36\n",
      "Epoch: 37, Discriminator Loss: 0.9751401543617249, Generator Loss: 1.4994851350784302\n",
      "Image saved for epoch 37\n",
      "Epoch: 38, Discriminator Loss: 0.9839275479316711, Generator Loss: 1.485529899597168\n",
      "Image saved for epoch 38\n",
      "Epoch: 39, Discriminator Loss: 0.981028139591217, Generator Loss: 1.4888391494750977\n",
      "Image saved for epoch 39\n",
      "Epoch: 40, Discriminator Loss: 0.9781954288482666, Generator Loss: 1.4895755052566528\n",
      "Image saved for epoch 40\n",
      "Epoch: 41, Discriminator Loss: 0.9838312864303589, Generator Loss: 1.4838334321975708\n",
      "Image saved for epoch 41\n",
      "Epoch: 42, Discriminator Loss: 0.9829555153846741, Generator Loss: 1.4774600267410278\n",
      "Image saved for epoch 42\n",
      "Epoch: 43, Discriminator Loss: 0.9787722826004028, Generator Loss: 1.4844622611999512\n",
      "Image saved for epoch 43\n",
      "Epoch: 44, Discriminator Loss: 0.980739414691925, Generator Loss: 1.4870526790618896\n",
      "Image saved for epoch 44\n",
      "Epoch: 45, Discriminator Loss: 0.9779066443443298, Generator Loss: 1.4866759777069092\n",
      "Image saved for epoch 45\n",
      "Epoch: 46, Discriminator Loss: 0.9779902696609497, Generator Loss: 1.488106608390808\n",
      "Image saved for epoch 46\n",
      "Epoch: 47, Discriminator Loss: 0.9740047454833984, Generator Loss: 1.4885125160217285\n",
      "Image saved for epoch 47\n",
      "Epoch: 48, Discriminator Loss: 0.9768250584602356, Generator Loss: 1.4888877868652344\n",
      "Image saved for epoch 48\n",
      "Epoch: 49, Discriminator Loss: 0.9698237180709839, Generator Loss: 1.5019404888153076\n",
      "Image saved for epoch 49\n"
     ]
    }
   ],
   "source": [
    "G_loss = []\n",
    "D_loss = []\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    d_epoch_loss = 0\n",
    "    g_epoch_loss = 0\n",
    "    count = len(dataloader)\n",
    "\n",
    "    for step, (img, _) in enumerate(dataloader):\n",
    "        img = img.to(device)\n",
    "        size = img.size(0)\n",
    "        random_noise = torch.randn(size, 100, device=device)\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_output = D(img)  \n",
    "        d_real_loss = criterion(real_output, torch.ones_like(real_output))   \n",
    "        d_real_loss.backward()\n",
    "        gen_img = G(random_noise)\n",
    "\n",
    "        fake_output = D(gen_img.detach())\n",
    "        d_fake_loss = criterion(fake_output, torch.zeros_like(fake_output))  \n",
    "        d_fake_loss.backward()\n",
    "\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        optimizer_D.step()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        fake_output = D(gen_img)\n",
    "        g_loss = criterion(fake_output, torch.ones_like(fake_output))      \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            d_epoch_loss += d_loss\n",
    "            g_epoch_loss += g_loss\n",
    "\n",
    "    with torch.no_grad():  # average loss\n",
    "        d_epoch_loss /= count\n",
    "        g_epoch_loss /= count\n",
    "        D_loss.append(d_epoch_loss)\n",
    "        G_loss.append(g_epoch_loss)\n",
    "        print(f'Epoch: {epoch}, Discriminator Loss: {d_epoch_loss}, Generator Loss: {g_epoch_loss}')\n",
    "        save_image(G, test_input, epoch)\n",
    "        #plot_image(G, test_input)\n",
    "        \n",
    "    torch.cuda.empty_cache() # Free memory after each epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
